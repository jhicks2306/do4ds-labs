## DevOps for Data Science project

In this project I built:
1. **Quarto website** and published it to GitHub pages
2. An **interactive dashboard** where the user can explore a basic machine learning model.

You can view the Quarto website here and a video of the interactive dahsboard is below. (I took the interactive dashboard down to avoid ongoing fees from AWs.)

This project used dummy data to practice some fundamental skills related to developer operations for data science.

Below summarises the skills practiced during this project:
- Created a Quarto webste using both R and Python environments.
- Moved data into a `DuckDB` database.
- Created an API to serve a Python machine-learning model using `vetiver`.
- Created a `Shiny` app to call the API.
- Added basic `logging` to the Shiny app.
- Deployed the Quarto site to `GitHub Pages`
- Added `GitHub Actions` to automate future deployment.
- Moved the machine-learning model into a `Docker` container.
- Configured `AWS` by standing up an EC2 server instance and S3 cloud storage.
- Logged into the remote server to set up `SSH`.
- Conducted basic `Linux Administration` to set up a remote user.
- Deployed the model API and Shiny app to the cloud using 'Shiny Server`.
- Used `NGINX` to set up a proxy so that the services were publicly available.
- Purchased a URL and user `DNS` to associate it with the remote server.
- Configured `HTTPS` on the server to make it secure.



